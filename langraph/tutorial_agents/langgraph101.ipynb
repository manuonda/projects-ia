{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6921a62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core import tools\n",
    "from langchain.tools import tool\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "load_dotenv(\"./.env\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "007e138a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'write_email', 'args': {'to': 'manuonda@gmail.com', 'subject': 'Eres un crack!', 'content': 'Hola,\\n\\nSolo quería tomarme un momento para decir que eres un auténtico crack. Sigue con el buen trabajo y esa actitud positiva.\\n\\n¡Saludos!'}, 'id': 'call_AyBDvC9NsDadiiBgMD5XBqdd', 'type': 'tool_call'}\n",
      "Name tool : write_email\n",
      "Args : {'to': 'manuonda@gmail.com', 'subject': 'Eres un crack!', 'content': 'Hola,\\n\\nSolo quería tomarme un momento para decir que eres un auténtico crack. Sigue con el buen trabajo y esa actitud positiva.\\n\\n¡Saludos!'}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Email sent to manuonda@gmail.com with subject Eres un crack! and content : Hola,\n",
       "\n",
       "Solo quería tomarme un momento para decir que eres un auténtico crack. Sigue con el buen trabajo y esa actitud positiva.\n",
       "\n",
       "¡Saludos!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tool \n",
    "def write_email(to: str, subject:str, content: str) -> str:\n",
    "    \"\"\"Write and send email\"\"\"\n",
    "    return f\"Email sent to {to} with subject {subject} and content : {content}\"\n",
    "\n",
    "model_with_tools = llm.bind_tools( [write_email] , parallel_tool_calls=False)\n",
    "output = model_with_tools.invoke(\"Envia un email a manuonda@gmail.com diciendo que es un crack\")\n",
    "\n",
    "print(output.tool_calls[0])\n",
    "print(f\"Name tool : {output.tool_calls[0]['name']}\")\n",
    "\n",
    "type(output)\n",
    "args = output.tool_calls[0]['args']\n",
    "print(f\"Args : {args}\")\n",
    "\n",
    "#call the tool\n",
    "result = write_email.invoke(args)\n",
    "Markdown(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "786466a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Sure, I can help draft an email for you. Could you please provide me with some details about the meeting or any specific points you would like to include in the response?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 66, 'total_tokens': 102, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-Bqq4szeQCmVtbBaL9DyEuudY0pwPn', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--aa7e1f69-3e93-4483-94c1-647792bf13fa-0' usage_metadata={'input_tokens': 66, 'output_tokens': 36, 'total_tokens': 102, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'request': \"Draft a response to my boss (boss@company.ai) about tomorrow's meeting\",\n",
       " 'email': 'Sure, I can help draft an email for you. Could you please provide me with some details about the meeting or any specific points you would like to include in the response?'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "class StateSchema(TypedDict):\n",
    "    request: str\n",
    "    email: str\n",
    "\n",
    "workflow = StateGraph(StateSchema)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def write_email_node(state: StateSchema) -> StateSchema:\n",
    "    # Imperative code that processes the request\n",
    "    output = model_with_tools.invoke(state[\"request\"])\n",
    "    print(output)\n",
    "    if output.tool_calls:\n",
    "      args = output.tool_calls[0]['args']\n",
    "      email = write_email.invoke(args)\n",
    "      return {\"email\": email}\n",
    "    else:\n",
    "        return {\"email\": output.content}\n",
    "\n",
    "\n",
    "\n",
    "workflow = StateGraph(StateSchema)\n",
    "workflow.add_node(\"write_email_node\", write_email_node)\n",
    "workflow.add_edge(START, \"write_email_node\")\n",
    "workflow.add_edge(\"write_email_node\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "app.invoke({\"request\": \"Draft a response to my boss (boss@company.ai) about tomorrow's meeting\"})#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc3a3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#should_continue \n",
    "from typing import Literal\n",
    "from langgraph.graph import MessagesState\n",
    "from email_assistant.utils import show_graph \n",
    "\n",
    "def call_llm(state: MessagesState) -> MessagesState:\n",
    "    \"\"\" Run LLM \"\"\"\n",
    "    output = model_with_tools.invoke(state['messages'])\n",
    "    return {\"messages\": [output]}\n",
    "\n",
    "def run_tool(state: MessagesState):\n",
    "    \"\"\"Performs the tool call\"\"\"\n",
    "    result = []\n",
    "    for tool_call in state[\"messages\"][-1].tools_calls:\n",
    "        observation = write_email.invoke(tool_call[\"args\"])\n",
    "        result.append({\"role\":\"tool\", \"content\":observation, \"tool_call_id\": tool_call[\"id\"]})\n",
    "    return {\"messages\": result}\n",
    "\n",
    "def should_continue(state:MessagesState)->Literal[\"run_tool\",\"__end__\"]:\n",
    "    \"\"\"Route to tool handler, or end if Done tool called\"\"\"\n",
    "    #GEt the las message\n",
    "    messages= state[\"messages\"]\n",
    "    last_message= messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tool\"\n",
    "      \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
